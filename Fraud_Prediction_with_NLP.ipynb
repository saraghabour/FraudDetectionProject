{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9167aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\ahmed sadek\\appdata\\roaming\\python\\python39\\site-packages (2.98)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\ahmed sadek\\appdata\\roaming\\python\\python39\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\ahmed sadek\\appdata\\roaming\\python\\python39\\site-packages (from pyttsx3) (304)\n",
      "Requirement already satisfied: comtypes in c:\\programdata\\anaconda3\\lib\\site-packages (from pyttsx3) (1.1.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe928fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement espeak (from versions: none)\n",
      "ERROR: No matching distribution found for espeak\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install espeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be8b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyttsx3\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import  pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X has feature names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59153aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fraud_detection_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a97673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature_engineer_df.pkl', 'rb') as f:\n",
    "    df= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5989341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1533542</th>\n",
       "      <td>154</td>\n",
       "      <td>2</td>\n",
       "      <td>259500.87</td>\n",
       "      <td>2602539.43</td>\n",
       "      <td>2862040.30</td>\n",
       "      <td>2277849.22</td>\n",
       "      <td>2018348.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185610</th>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>26757.98</td>\n",
       "      <td>108635.83</td>\n",
       "      <td>81877.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005197</th>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>11223.25</td>\n",
       "      <td>40997.65</td>\n",
       "      <td>29774.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822808</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>284852.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1526139.91</td>\n",
       "      <td>1810991.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671317</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>27152.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173345</th>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>609102.43</td>\n",
       "      <td>11601.00</td>\n",
       "      <td>620703.43</td>\n",
       "      <td>22711.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097574</th>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>196144.10</td>\n",
       "      <td>509036.34</td>\n",
       "      <td>312892.24</td>\n",
       "      <td>1033290.92</td>\n",
       "      <td>1229435.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946939</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>196712.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1024665.07</td>\n",
       "      <td>1221377.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664472</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>317420.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3013526.82</td>\n",
       "      <td>3330947.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442149</th>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>78910.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>537847.37</td>\n",
       "      <td>616757.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         step  type     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "1533542   154     2  259500.87     2602539.43      2862040.30      2277849.22   \n",
       "6185610   567     1   26757.98      108635.83        81877.85            0.00   \n",
       "3005197   232     1   11223.25       40997.65        29774.40            0.00   \n",
       "822808     40     3  284852.00           0.00            0.00      1526139.91   \n",
       "671317     36     1   27152.63           0.00            0.00            0.00   \n",
       "1173345   132     2  609102.43       11601.00       620703.43        22711.00   \n",
       "3097574   235     0  196144.10      509036.34       312892.24      1033290.92   \n",
       "946939     44     0  196712.81           0.00            0.00      1024665.07   \n",
       "2664472   210     0  317420.65           0.00            0.00      3013526.82   \n",
       "3442149   257     0   78910.43           0.00            0.00       537847.37   \n",
       "\n",
       "         newbalanceDest  isFraud  \n",
       "1533542      2018348.35        0  \n",
       "6185610            0.00        0  \n",
       "3005197            0.00        0  \n",
       "822808       1810991.91        0  \n",
       "671317             0.00        0  \n",
       "1173345            0.00        0  \n",
       "3097574      1229435.02        0  \n",
       "946939       1221377.88        0  \n",
       "2664472      3330947.47        0  \n",
       "3442149       616757.80        0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0543b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('PS_20174392719_1491204439457_log.csv'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fb5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd = pd.read_csv('PS_20174392719_1491204439457_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7fb291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_transaction_description(row):\n",
    "    return(f\"At step {row['step']}, a {row['type']} of ${row['amount']} was made \"\n",
    "           f\"from {row['nameOrig']}(Old Balance: $ {row['oldbalanceOrg']}, New balance: $ {row['newbalanceOrig']})\"\n",
    " f\"to {row['nameDest']} (Old Balance: $ {row['oldbalanceDest']}, New balance: $ {row['newbalanceDest']}) .\")\n",
    "\n",
    "# Apply the function to create a new 'description' column\n",
    "dfd['description'] = dfd.apply(creat_transaction_description, axis=1)  \n",
    "\n",
    "# Display the first few descriptions\n",
    "print(dfd[['description']].head(5))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Lemmatizer & Stop Words\n",
    "lemmatizer = WordNetLemmatizer()  # Create a lemmatizer Object\n",
    "stop_words = set(stopwords.words('english'))   # Get the List of Stop Words\n",
    "\n",
    "# Function to Preprocess \n",
    "def preprocess_text(text):\n",
    "     # Step 1: Tokenize\n",
    "    tokens = word_tokenize(text.lower()) \n",
    "\n",
    "    # Step 2: Lemmatzie and remove stop words\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum() and token not in stop_words]  \n",
    "\n",
    "    # Step 3: Join tokens back into a single string\n",
    "    return ' '.join(tokens)  \n",
    "\n",
    "\n",
    "# Apply preprocessing to the 'description' column\n",
    "df['cleaned_description'] = df['description'].apply(preprocess_text)\n",
    "print(df[['cleaned_description']].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 16\n",
    "sample_size = 5000\n",
    "\n",
    "# Initialize a list to store each sample\n",
    "samples_list = []\n",
    "\n",
    "# Loop through 16 times to get different random samples\n",
    "for i in range(num_iterations):\n",
    "    \n",
    "    # Randomly sample 5000 rows in each iteration\n",
    "    df_sample = df.sample(n=sample_size, random_state=i)\n",
    "    df_sample = df_sample.reset_index(drop=True)\n",
    "    \n",
    "    # Store the sampled data\n",
    "    samples_list.append(df_sample)\n",
    "    \n",
    "    # Display the shape of each sample\n",
    "    print(f\"Sample {i+1} shape: {df_sample.shape}\")\n",
    "\n",
    "# After this, 'samples_list' contains 16 separate DataFrames each with 5000 randomly selected rows.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Intialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)   \n",
    "\n",
    "# Loop through each sample in the list and apply TF-IDF\n",
    "for i, sample in enumerate(samples_list):\n",
    "    \n",
    "    # Ensure that 'cleaned_description' column exists in the sample\n",
    "    if 'cleaned_description' in sample.columns:\n",
    "        \n",
    "        # Fit and transform the 'cleaned_description' column using TF-IDF\n",
    "        X_tfidf = vectorizer.fit_transform(sample['cleaned_description'])\n",
    "        \n",
    "        # Convert the sparse matrix to a dense array\n",
    "        X_tfidf_array = X_tfidf.toarray()\n",
    "        \n",
    "        # Display the shape of the TF-IDF matrix for each sample\n",
    "        print(f\"Sample {i+1} TF-IDF shape: {X_tfidf_array.shape}\")\n",
    "    else:\n",
    "        print(f\"Sample {i+1} does not contain 'cleaned_description' column.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe963e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text):\n",
    "    engine = pyttsx3.init()   # Initialize the pyttsx3\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()   # Ensure the speech is processed before moving on to the next iteration\n",
    "    engine.setProperty('rate', 150)  # Speed of speech\n",
    "    engine.setProperty('volume', 1)  # Volume level (0.0 to 1.0)\n",
    "\n",
    "# Use 'samples_list' which is a list of DataFrames, each containing the 'cleaned_description' and numerical features.\n",
    "for i, df_sample in enumerate(samples_list):\n",
    "    \n",
    "    #Select Numerical features\n",
    "    numerical_features = df_sample[['amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest' ]].values\n",
    "    \n",
    "    #Combine TF-IDF features with numerical features\n",
    "    X_combined = np.hstack((X_tfidf.toarray(), numerical_features))\n",
    "    \n",
    "    # Define the target variable: \"isFraud\"\n",
    "    y = df_sample['isFraud']\n",
    "    \n",
    "    # Split data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    #Train a Random Forest model\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"Sample {i+1} Model Accuracy: {accuracy}\")\n",
    "    \n",
    "    # Print and convert accuracy to speech\n",
    "    text_to_speech(f\"Sample {i+1} Its Model Accuracy is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a98cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf76a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a3867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ecedb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69268043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ef3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
